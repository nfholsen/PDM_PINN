{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div style='background-image: url(\"header.png\") ; padding: 0px ; background-size: cover ; border-radius: 5px ; height: 250px'>\n",
        "    <div style=\"float: right ; margin: 50px ; padding: 20px ; background: rgba(255 , 255 , 255 , 0.7) ; width: 50% ; height: 150px\">\n",
        "        <div style=\"position: relative ; top: 50% ; transform: translatey(-50%)\">\n",
        "            <div style=\"font-size: xx-large ; font-weight: 900 ; color: rgba(0 , 0 , 0 , 0.8) ; line-height: 100%\">Tutorial by Mondaic</div>\n",
        "            <div style=\"font-size: large ; padding-top: 20px ; color: rgba(0 , 0 , 0 , 0.5)\">For Salvus version 0.11.25</div>\n",
        "        </div>\n",
        "    </div>\n",
        "</div>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Mesh Quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Introduction\n",
        "\n",
        "In this notebook, you build a piecewise structured mesh using a 1D model read from a file and automatic placement of refinements. Play with the input parameters to find out:\n",
        "\n",
        " - Which way do you get the best mesh?\n",
        " - Does this change for 3D?\n",
        " - Does it depend on the frequency?\n",
        "\n",
        "The automatic placement considers a number of criteria. If any of them is not met, the refinement is pushed further downwards. This is based on the assumption, that velocities increase with depth in most models (which we enforce by making the size function monotonous before calculating element sizes). The criteria are:\n",
        "\n",
        " - mimimum resolution in horizontal direction\n",
        " - no refinement directly at the surface or the bottom\n",
        " - no multiple refinements at the same depth\n",
        " - no refinement in very thin layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# set up the notebook\n",
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10, 8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Building the mesh\n",
        "\n",
        "The model file, edit as you like with colums in units of km, km/s and kg/m^3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile three_layer.bm\n",
        "NAME         three_layer\n",
        "UNITS        km\n",
        "COLUMNS      depth rho vp vs\n",
        "    0.0   2.6     1.7     1.0\n",
        "   10.0   2.6     1.7     1.0\n",
        "   10.0   3.0     3.5     2.2\n",
        "   15.0   3.0     3.5     2.2\n",
        "   15.0   3.5     3.8     2.6\n",
        "  100.0   3.5     3.8     2.6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Read the model file and plot the seismic velocities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from salvus.mesh.models_1D import model\n",
        "\n",
        "model = model.read(\"three_layer.bm\")\n",
        "model.plot_vp_vs_profile(depth=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The model provides the discontinuities and functionality to compute element sizes according to the resolution criterion. Internally, we work with normalized coordinates, hence the need to scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\n",
        "    \"discontinuities:\",\n",
        "    [\"{:.1f}\".format(i) for i in model.discontinuities * model.scale],\n",
        ")\n",
        "print(\n",
        "    \"element size:   \",\n",
        "    [\n",
        "        \"{:.1f}\".format(i)\n",
        "        for i in model.get_edgelengths(\n",
        "            dominant_period=1.0, elements_per_wavelength=2\n",
        "        )\n",
        "        * model.scale\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Exercise: Vary hmax_refinement, refinement_style and refinement_top_down to make the best mesh.\n",
        "\n",
        "Note: Top down approach means minimizing number of elements at the surface at the cost of more elements at the bottom (default). If False, bottom up approach is used, that is minimizing number of elements at the bottom at the cost of more elements at the surface. Top down leads to fewer refinement. Which one is more efficient depends on the velocity model and refinement style."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "frequency = 0.1  # maximum frequency in Hz\n",
        "max_x = 200000.0  # Domain size in horizontal direction in m\n",
        "hmax_refinement = (\n",
        "    1.5  # critertion to avoid refinements in thin layers, need to be > 1.0,\n",
        ")\n",
        "# default is 1.5, smaller value = more aggressive\n",
        "refinement_style = \"doubling\"  # 'doubling' or 'tripling'\n",
        "refinement_top_down = True  # True or False\n",
        "ndim = 2  # 2 or 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from salvus.mesh.skeleton import Skeleton\n",
        "\n",
        "if ndim == 2:\n",
        "    horizontal_boundaries = (np.array([0]), np.array([max_x / model.scale]))\n",
        "elif ndim == 3:\n",
        "    horizontal_boundaries = (\n",
        "        np.array([0, 0]),\n",
        "        np.array([max_x / model.scale, max_x / model.scale]),\n",
        "    )\n",
        "\n",
        "sk = Skeleton.create_cartesian_mesh(\n",
        "    model.discontinuities,\n",
        "    model.get_edgelengths(1.0 / frequency),\n",
        "    hmax_refinement=hmax_refinement,\n",
        "    horizontal_boundaries=horizontal_boundaries,\n",
        "    refinement_top_down=refinement_top_down,\n",
        "    refinement_style=refinement_style,\n",
        "    ndim=ndim,\n",
        ")\n",
        "m = sk.get_unstructured_mesh()\n",
        "m.find_side_sets(mode=\"cartesian\")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Judging the quality\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### a) Equiangular Skewness\n",
        "A popular quality measure in the community is the equiangular skewness, which is defined as\n",
        "\n",
        "\\begin{align}\n",
        "\\text{skew} = \\max \\left(\n",
        "\\frac{\\theta_{\\max} - \\theta_{e}}{180 - \\theta_{e}},\n",
        "\\frac{\\theta_{e} - \\theta_{\\min}}{\\theta_{e}}\n",
        "\\right).\n",
        "\\end{align}\n",
        "\n",
        "Quality meshes must not have skewed elements (skewness <~ 0.75), a single bad element can cause instability in the time extrapolation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m.plot_quality(\"equiangular_skewness\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Locate skewed elements visually:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m.attach_field(\n",
        "    \"equiangular_skewness\", m.compute_mesh_quality(\"equiangular_skewness\")\n",
        ")\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### b) resolution criterion\n",
        "Another important quality criterion is the resolution of the waves at the specified frequency, that is the elements need to be smaller than a constant times the local wavelength:\n",
        "\n",
        "\\begin{align}\n",
        "h_{\\max} < \\frac{\\lambda}{n} = \\frac{v_{s}}{f n},\n",
        "\\end{align}\n",
        "\n",
        "where $f$ is the frequency, $h_{\\max}$ is the longest edge of the element an $n$ is the number of elements used per wavelength (typically 2). This criterion is not strict in the sense that it is no problem if it is violated by a few elements.\n",
        "\n",
        "As this was an input to the mesh generation routine, we should expect that this criterion is fulfilled here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hmax = model.get_edgelengths_radius(\n",
        "    m.get_element_centroid()[:, -1], dominant_period=1.0 / frequency\n",
        ")\n",
        "\n",
        "h = m._hmax() / hmax\n",
        "print(\"h_min = {0}, h_max = {1}\".format(h.min(), h.max()))\n",
        "m.attach_field(\"h\", h)\n",
        "\n",
        "m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### c) Simulation Cost\n",
        "\n",
        "We can estimate the simulation cost to be proportional to number of elements / time step to compare different meshes. The largest stable time step in explicit time stepping schemes can be estimated based on the Courant criterion:\n",
        "\n",
        "\\begin{align}\n",
        "C = \\frac{v_{p} \\Delta t}{h_{\\min}} < C_{\\max},\n",
        "\\end{align}\n",
        "\n",
        "where $h_{\\min}$ is the minimum point distance in each element, $\\Delta t$ the time step and $C$ the Courant number. $C_{\\max}$ depends on the time scheme and a typical value is $0.4$.\n",
        "\n",
        "While the $h_{\\min}$ is often just computed based on the edgelengths of each element, salvus has a more accurate estimator that takes  the deformation of the elements into account. With this more accurate cost estimate, one may find even more skewed elements acceptable, as long as they do not result in an unfeasible time step.\n",
        "\n",
        "Note that the $\\Delta t$ estimated here needs to be scaled by the courant number and GLL point distance for the order of the spectral elements to get the final time step.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "z = m.get_element_centroid()[:, -1]\n",
        "vp = model.get_elastic_parameter(\"VP\", z, scaled=False)\n",
        "\n",
        "# edgelength based estimate\n",
        "dt1, dt1_elem = m.compute_dt(vp, fast=True)\n",
        "\n",
        "# more accurate estimate\n",
        "dt2, dt2_elem = m.compute_dt(vp, fast=False)\n",
        "\n",
        "print(\"number of elements:   %i\" % m.nelem)\n",
        "print(\"edgelength based dt:  %.2f\" % dt1)\n",
        "print(\"accurate dt:          %.2f\" % dt2)\n",
        "print(\"cost factor:          %.1f\" % (m.nelem / dt2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "plot dt over the mesh to locate the minimum:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m.attach_field(\"dt1\", dt1_elem)\n",
        "m.attach_field(\"dt2\", dt2_elem)\n",
        "m"
      ]
    }
  ],
  "metadata": {
    "jupytext": {
      "cell_metadata_json": true,
      "formats": "ipynb,py:light"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}